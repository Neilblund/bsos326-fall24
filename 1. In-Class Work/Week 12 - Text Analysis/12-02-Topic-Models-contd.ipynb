{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "207efa25-c5e2-4992-b9ad-6c753035cfb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8297ca04-9246-47db-bc3c-4fe3f98c35db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "import re\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import SnowballStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import string\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "import pyLDAvis.lda_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6e2cc9-b342-4397-96e5-b00777276baf",
   "metadata": {},
   "source": [
    "Importing some utility functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d698452a-89d4-4422-b871-9103fa1d9612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lda_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7517835-41b4-4d52-a078-e1b0af82dded",
   "metadata": {},
   "source": [
    "Re-doing the pre-processing steps from the prior class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41b99c6d-360a-4709-811a-787b43162875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>year(date)</th>\n",
       "      <th>hyperlink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cnn.com/2020/06/11/politics/donald...</td>\n",
       "      <td>Trump is getting his reopening even as the vir...</td>\n",
       "      <td>\\n      President Donald Trump is getting what...</td>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>CNN</td>\n",
       "      <td>2020</td>\n",
       "      <td>&lt;a href=https://www.cnn.com/2020/06/11/politic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.cnn.com/2020/05/07/politics/state-...</td>\n",
       "      <td>Supply shortages remain a top concern as state...</td>\n",
       "      <td>\\n      Since mid-March, Washington state, one...</td>\n",
       "      <td>2020-05-07</td>\n",
       "      <td>CNN</td>\n",
       "      <td>2020</td>\n",
       "      <td>&lt;a href=https://www.cnn.com/2020/05/07/politic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.cnn.com/2020/03/19/politics/mcconn...</td>\n",
       "      <td>Exclusive: McConnell defends crafting $1 trill...</td>\n",
       "      <td>\\n      Senate Majority Leader Mitch McConnell...</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>CNN</td>\n",
       "      <td>2020</td>\n",
       "      <td>&lt;a href=https://www.cnn.com/2020/03/19/politic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.cnn.com/2020/06/18/politics/new-yo...</td>\n",
       "      <td>New York City passes rent freeze for stabilize...</td>\n",
       "      <td>\\n      A rent freeze for rent-stabilized apar...</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>CNN</td>\n",
       "      <td>2020</td>\n",
       "      <td>&lt;a href=https://www.cnn.com/2020/06/18/politic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.cnn.com/2020/06/11/politics/senate...</td>\n",
       "      <td>GOP-led panel moves to remove Confederate name...</td>\n",
       "      <td>\\n      A Senate plan to remove names of Confe...</td>\n",
       "      <td>2020-06-11</td>\n",
       "      <td>CNN</td>\n",
       "      <td>2020</td>\n",
       "      <td>&lt;a href=https://www.cnn.com/2020/06/11/politic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.cnn.com/2020/06/11/politics/donald...   \n",
       "1  https://www.cnn.com/2020/05/07/politics/state-...   \n",
       "2  https://www.cnn.com/2020/03/19/politics/mcconn...   \n",
       "3  https://www.cnn.com/2020/06/18/politics/new-yo...   \n",
       "4  https://www.cnn.com/2020/06/11/politics/senate...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Trump is getting his reopening even as the vir...   \n",
       "1  Supply shortages remain a top concern as state...   \n",
       "2  Exclusive: McConnell defends crafting $1 trill...   \n",
       "3  New York City passes rent freeze for stabilize...   \n",
       "4  GOP-led panel moves to remove Confederate name...   \n",
       "\n",
       "                                                text        date source  \\\n",
       "0  \\n      President Donald Trump is getting what...  2020-06-11    CNN   \n",
       "1  \\n      Since mid-March, Washington state, one...  2020-05-07    CNN   \n",
       "2  \\n      Senate Majority Leader Mitch McConnell...  2020-03-19    CNN   \n",
       "3  \\n      A rent freeze for rent-stabilized apar...  2020-06-18    CNN   \n",
       "4  \\n      A Senate plan to remove names of Confe...  2020-06-11    CNN   \n",
       "\n",
       "   year(date)                                          hyperlink  \n",
       "0        2020  <a href=https://www.cnn.com/2020/06/11/politic...  \n",
       "1        2020  <a href=https://www.cnn.com/2020/05/07/politic...  \n",
       "2        2020  <a href=https://www.cnn.com/2020/03/19/politic...  \n",
       "3        2020  <a href=https://www.cnn.com/2020/06/18/politic...  \n",
       "4        2020  <a href=https://www.cnn.com/2020/06/11/politic...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "articles = pd.read_csv('https://github.com/Neilblund/APAN/raw/main/news_sample.csv')\n",
    "articles['hyperlink']=articles.apply(axis=1, func = lambda x: f'<a href={x.url}>{x.headline}</a>')\n",
    "\n",
    "# stripping some excess whitespace\n",
    "articles['headline'] = articles.headline.str.strip()\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfbd2cb3-0e18-4f7f-9158-0c4cbbd14977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neilb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = articles.text.str.lower().reset_index().text\n",
    "# tokenizer that splits words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# word stemming\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "# english stop words\n",
    "# stem the stopwords to ensure they're removedb\n",
    "eng_stopwords = [tokenizer.tokenize(s)[0] for s in  stopwords.words('english')]\n",
    "\n",
    "def tokenize(text):   \n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    return [stemmer.stem(token) for token in tokens if token not in eng_stopwords]\n",
    "\n",
    "vectorizer = CountVectorizer(analyzer= \"word\", # unit of features are single words rather then phrases of words \n",
    "                             tokenizer = tokenize,\n",
    "                             ngram_range=(0,1), # Tokens are individual words for now\n",
    "                             strip_accents='unicode',\n",
    "                             max_df = 0.1, # maximum number of documents in which word j occurs. \n",
    "                             min_df = .0025 # minimum number of documents in which word j occurs. \n",
    "                            )\n",
    "\n",
    "\n",
    "\n",
    "bag_of_words = vectorizer.fit_transform(text) \n",
    "features = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bafe3a-6fbe-4b44-a9a9-bd65e3d8ec04",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "\n",
    "Interpreting a topic model can feel disconcertingly subjective: we chose a number of topics arbitrarily, and then we interepreted and labeled the output based on an eqaully subjective intepretation of our topic-word distributions. To some extent, we just have to live with some uncertainty, but we should at least be aware of how we can make adujustments to a model and what we can do to improve them if needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599c7de-4970-4d23-b5d5-28badf1eabdb",
   "metadata": {},
   "source": [
    "### Adjusting the number of topics\n",
    "\n",
    "What constitutes the \"correct\" number of topics for LDA is often a matter of interpretation. In general, setting a higher number of topics (50-200) may allow you to capture more nuance, while setting a lower number (15-40) can make the output easier to interpret. If you find that you have a lot of topics that don't seem to hold together, it may be a sign that you need to adjust the number and see how things look.\n",
    "\n",
    "The one thing you can be certain about is that a model with more topics will noticeably slower than models with just a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53ac9b2-fde5-4a31-99d7-9a8126771fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_topics = LatentDirichletAllocation(\n",
    "                                # setting a small number of topics:\n",
    "                                n_components = 3, \n",
    "                                random_state = 1231) \n",
    "result=few_topics.fit_transform(bag_of_words)\n",
    "\n",
    "# getting top terms\n",
    "topterms=lda_functions.get_top_words(few_topics, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f69b2c-01ce-4242-815e-bec2081df9ab",
   "metadata": {},
   "source": [
    "### Adjusting our priors\n",
    "\n",
    "You might notice the `topic_word_prior` and `doc_topic_priors` were added as arguments to our model. What do these do? \n",
    "\n",
    "- the `doc_topic_prior` parameter controls the \"smoothness\" of our document-topic distributions. A higher number will cause the document-topic distributions to be more evenly distributed across all of our topics. \n",
    "- the `topic_word_prior` parameter will cause the topic-word distributions to have a more even distribution across each term.\n",
    "\n",
    "Anecdotally: the topic word priors are usually fine with their defaults, but you might find that adjusting the `doc_topic_prior` improves your results. \n",
    "\n",
    "Here's an example using a very low value for the `doc_topic_prior` (note that I'm only using 200 documents here to make things run quickly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5691cc9e-a071-4d48-8a3f-0f6d58bb5b33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create LDA model object\n",
    "k = 10\n",
    "lda_low_doc_topic_prior = LatentDirichletAllocation(n_components = k, \n",
    "                                random_state = 123, \n",
    "                                doc_topic_prior = .000001) \n",
    "\n",
    "# Fit to just 200 documents\n",
    "doctopic_low = lda_low_doc_topic_prior.fit_transform(bag_of_words[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f9575-ea93-4ed1-9e3f-2068dbb3c8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(doctopic_low).head().style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243de329-c471-47f9-9f87-100e02f4551a",
   "metadata": {},
   "source": [
    "Compare the output to this model with a very high value for the `doc_topic_prior`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b815af0-74c7-4b7c-b9d1-271db1f2df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "lda_high_doc_topic_prior = LatentDirichletAllocation(n_components = k, \n",
    "                                random_state = 123, \n",
    "                                doc_topic_prior = 1) \n",
    "\n",
    "# fitting on the first 200 documents\n",
    "doctopic_high = lda_high_doc_topic_prior.fit_transform(bag_of_words[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e55a2-6bd9-4f24-b5de-1eacff988fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(doctopic_high).head().style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167be622-d95a-4abd-8050-c8724fc572e8",
   "metadata": {},
   "source": [
    "In a sense, the values set on the hyper-parameters reflect some pre-existing assumptions about the data: if you think that the documents in your corpus are going to focus on just one or two topics, then you should set `doc_topic_prior` to a low number. If you think each document will cover a lot of issues, then you might want to set this higher.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5111aa-0426-4107-bd92-65b57bb01ee6",
   "metadata": {},
   "source": [
    "### How do know if we need to make adjustments?\n",
    "\n",
    "There are some \"objective\" metrics that we can use \n",
    "One method that has been used to assess topic quality is called a \"word intrustion\" test. This works by selecting the top key words from each topic, then adding a randomly selected word to each list and asking some humans to if they can find the term that doesn't belong. If a model is generating coherent topics, you would expect people to be able to spot intruders fairly easily. \n",
    "\n",
    "You can try out a toy version of this with the function below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28432062-7668-4851-9055-f9872c16a513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_intruder(lda, features, n_terms=5):\n",
    "    score = []\n",
    "    for topic in range(lda.components_.shape[0]):\n",
    "        indices = random.sample(range(n_terms+1), n_terms+1)\n",
    "        # Sorting and finding top keyword\n",
    "        word_idx = np.argsort(lda.components_[topic])[::-1][:n_terms]\n",
    "        keywords = [features[i] for i in word_idx]\n",
    "        keywords.append(random.choice(features))\n",
    "        keys = '\\n'.join([str(i) + '.' + keywords[j] for i, j in enumerate(indices)] )\n",
    "        print('Identify the word that does not belong\\n' + keys, end='')\n",
    "        a = input()\n",
    "        if a =='q':\n",
    "            break\n",
    "        try:\n",
    "            guess = indices[int(a)]\n",
    "            score.append(int(guess==5))\n",
    "        except:\n",
    "            print('')\n",
    "        clear_output(wait=False)\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5a78c2-b12d-4c36-abd3-51fc74154fb4",
   "metadata": {},
   "source": [
    "Here's an example when applying it to a model with bad parameters: not enough topics, unreasonably high values on the priors, and using only 200 documents for training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94b3a00-4bb5-4a95-ae7c-fec7b532f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "bad_model =  LatentDirichletAllocation(n_components = k, \n",
    "                                random_state = 123, \n",
    "                                doc_topic_prior = 1,\n",
    "                                topic_word_prior = 1\n",
    "                                      ) \n",
    "\n",
    "# Fit using data (bag_of_words)\n",
    "bad_fitted = bad_model.fit_transform(bag_of_words[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963a0b9-0734-41e6-8abd-2a50994aeefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter \"q\" to quit\n",
    "guesses=topic_intruder(bad_model, features)\n",
    "# calculate the % correct across all topics\n",
    "np.mean(guesses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49332933-2053-4d36-bf56-d14dfa69a8a7",
   "metadata": {},
   "source": [
    "## Improving the pre-processing\n",
    "\n",
    "One final area where we can potentially make improvements is by changing our pre-processing steps. We'll explore a couple of options below.\n",
    "\n",
    "### N-grams - Adding context by creating N-grams\n",
    "Obviously, reducing a document to a bag of words means losing much of its meaning - we put words in certain orders, and group words together in phrases and sentences, precisely to give them more meaning. If you follow the processing steps we've gone through so far, splitting your document into individual words, you'll end up with terms like \"north\" and \"carolina\" being handled as totally separate terms when they probably should be counted together. \n",
    "\n",
    "One way to address this is to break down each document similarly, but rather than treating each word as an individual unit, treat each group of 2 words, or 3 words, or n words, as a unit. We call this a \"bag of n-grams,\" where n is the number of words in each chunk. Then you can analyze which groups of words commonly occur together (in a fixed order).\n",
    "\n",
    "We can make this change by adjusting the `ngram_range` argument for the `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e669d72-1746-4440-a686-8cdc6d09b92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer= \"word\", # unit of features are single words rather then phrases of words \n",
    "                            tokenizer=tokenize, # function to create tokens\n",
    "                            strip_accents='unicode',\n",
    "                            max_df = 0.1, # maximum number of documents in which word j occurs. \n",
    "                            min_df = .0025 # minimum number of documents in which word j occurs. \n",
    "                            )\n",
    "\n",
    "# Creating bag of words\n",
    "bag_of_ngrams = vectorizer.fit_transform(text)\n",
    "ngram_features = vectorizer.get_feature_names_out()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a37b8e-7393-446d-b73b-d4277261b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice this is much larger!\n",
    "\n",
    "bag_of_ngrams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e989631-5a92-4013-bfd0-e9346c006c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting LDA model\n",
    "bigram_lda = LatentDirichletAllocation(n_components = 15, \n",
    "                                random_state=999) \n",
    "doctopic = bigram_lda.fit_transform( bag_of_ngrams )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019937aa-380a-41d3-84fa-c6e00d7f9d60",
   "metadata": {},
   "source": [
    "<b style=\"color:red;\"> Question 1: use the `get_top_words` function to find the top terms from the `bigram_lda` model. See if you spot any of the bi-grams in the list of most likely terms </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab81dcbf-dc0a-4648-a4a3-ebc8ff9e9997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a63e1088-ab7e-469b-9ac1-22f586b7733c",
   "metadata": {},
   "source": [
    "Or we can use the LDA visualization tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6058e4-ae76-4960-9cf6-84991b6a77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = pyLDAvis.lda_model.prepare(bigram_lda, bag_of_ngrams, vectorizer, mds='tsne', sort_topics=False, n_jobs = -1)\n",
    "word_info = panel.topic_info\n",
    "\n",
    "#To save panel in html\n",
    "pyLDAvis.save_html(panel, 'bigram_lda.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eaafb7-0acc-4072-9391-eb275684b6b1",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Another possibility is to use lemmatization instead of stemming to trim our terms. Recall that lemmatization, unlike word-stemming, attempts to identify the actual dictionary-based root word of a term rather than hapharzardly lopping off the word endings. Its much slower, but it can improve both accuracy and readability of text models. We could simply replace our original tokenizer function with a function that splits each word and lemmatizes it. However, since this is slow, I've run the code ahead of time and stored the results in the `processed_articles.csv`, but you could run the code below to replicate the steps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a8a756-4d66-4fe1-9595-04592d876f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for lemmatization with part of speech tagging. \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function that converts NLKT tags to a tag format used by wordnet\n",
    "def nltk_pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_pos_tagger(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    \n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return ' '.join(lemmatized_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce61ed4c-edaf-4727-90f7-cb45af18db60",
   "metadata": {},
   "source": [
    "You would uncomment the code in these lines to actually do the lemmatization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6554ca13-4703-4bd5-9bd9-4049c1ace671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then just run this to add to the existing column:\n",
    "# articles['lemmatized'] =  [lemmatize_sentence(i) for i in articles.text]\n",
    "# and then save your results: \n",
    "# articles.to_csv('processed_articles.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd6068-9418-401c-a119-571026b9f94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_articles =pd.read_csv(\"processed_articles.csv\")\n",
    "articles = articles.merge(lemmatized_articles, on='url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4daed3b2-d7b2-40ec-97cf-292611e762ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the lemmatized results\n",
    "articles.lemmatized[1][:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d70162-9f22-42d0-a152-3d86bb39f8c8",
   "metadata": {},
   "source": [
    "Now we'll apply the `CountVectorizer` function again and train a model using unigrams and bigrams on the lemmatized data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fe9f0-1766-4ab6-95b6-d5d07b2ba4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer= \"word\", # unit of features are single words rather then phrases of words \n",
    "                            ngram_range=(0,2), # Allow for bigrams\n",
    "                            strip_accents='unicode',\n",
    "                            stop_words = eng_stopwords,\n",
    "                            max_df = 0.1, # maximum number of documents in which word j occurs. \n",
    "                            min_df = .0025 # minimum number of documents in which word j occurs. \n",
    "                            )\n",
    "\n",
    "# Creating bag of words\n",
    "bag_of_lemma = vectorizer.fit_transform(lemmatized_articles.lemmatized) \n",
    "lemma_features = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f31ceb-0eae-4959-b008-9b3e0fcfc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_lemma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b83fd3-10cc-4608-9c07-dfdab8ac29b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting LDA model\n",
    "lemma_lda = LatentDirichletAllocation(n_components = 15, \n",
    "                                     random_state=999) \n",
    "doctopic = lemma_lda.fit_transform( bag_of_lemma )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885ff673-f8f8-4770-b5ec-455cdc716a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_lemma = lda_functions.get_top_words(lemma_lda, lemma_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9275ce5a-6e4f-4e29-867d-a0216e4f93e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda_functions.get_top_docs(doctopic, n_docs=2, docnames=articles.hyperlink).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa1ba91-1f7d-48a6-8fa1-0df005e1860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = pyLDAvis.lda_model.prepare(lemma_lda, bag_of_lemma, vectorizer, mds='tsne', sort_topics=False, n_jobs = -1)\n",
    "word_info = panel.topic_info\n",
    "\n",
    "#To save panel in html\n",
    "pyLDAvis.save_html(panel, 'lemma_lda.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10417063-d5a5-40bb-8b8d-4fd9bc53a0d5",
   "metadata": {},
   "source": [
    "### TF-IDF - Weighting terms based on frequency\n",
    "\n",
    "One additional step we can add in cleaning and processing our text data is **Term Frequency-Inverse Document Frequency (TF-IDF)**. TF-IDF is based on the idea that the words (or terms) that are most related to a certain topic will occur frequently in documents on that topic, and infrequently in unrelated documents.  TF-IDF re-weights words so that we emphasize words that are unique to a document and suppress words that are common throughout the corpus by inversely weighting terms based on their frequency within the document and across the corpus.\n",
    "\n",
    "Recall that our data might look something like this:\n",
    "\n",
    "|document ID|about|america|author|ask|...|\n",
    "|-|-|-|-|-|-|\n",
    "|1|0|0|0|0|...|\n",
    "|2|0|1|0|0|...|\n",
    "|3|0|0|3|0|...|\n",
    "|4|1|0|0|0|...|\n",
    "|5|0|0|0|2|...|\n",
    "|...|...|...|...|...|...|\n",
    "\n",
    "The values that are in the cells are the term frequencies. TF-IDF takes those values and re-weights them by the inverse of how often they occur in other documents. So, for example, if the term occurs in many other documents, the term frequency would be close to 1 (since the fraction of documents the term occurs in is close to 1). However, if the term occurs only in a smaller fraction of documents (such as 1/10th of documents), then the term frequency is multiplied by a much larger number (since we use the inverse document frequency).\n",
    "\n",
    "Let's look at how to use TF-IDF:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e2eec-d115-464d-91d9-c37ffc3a75fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use TfidfTransformer to re-weight bag of words \n",
    "transformer = TfidfTransformer(norm = None, smooth_idf = True, sublinear_tf = True)\n",
    "tfidf = transformer.fit_transform(bag_of_lemma)\n",
    "\n",
    "# Fitting LDA model\n",
    "tf_lda = LatentDirichletAllocation(n_components = 15, learning_method='online') \n",
    "doctopic = tf_lda.fit_transform(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823a8ab3-6980-4f97-acd1-02d7fc69cadb",
   "metadata": {},
   "source": [
    "<b style=\"color:red;\"> Question 2: use the `get_top_words` function to find the top terms from the `tf_lda` model. What differences, if any, do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a61c04a-967d-4e3d-a412-9e438e3aa70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b91aff-dc3c-4441-8e88-91bb1f918358",
   "metadata": {},
   "source": [
    "# Example of a grid search\n",
    "\n",
    "As I mentioned above: there's really no generally agreed-upon objective method for assessing the quality of a topic model, but there are some commonly used metrics. \n",
    "\n",
    "If you're interested in trying to optimize a model (and you have an hour or so to burn) you can try using a grid-search to run multiple models and compare them in terms of perplexity (which measures how well the model predicts words) and coherence (which measures how often words in the same topic appear together in documents). \n",
    "\n",
    "Scikitlearn doesn't have great support for either of these methods, but you can do it with the `tmtoolkit` module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8b3355-8105-405d-bfbc-f5c94a853eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install if you don't already have it\n",
    "%pip install -U \"tmtoolkit[recommended]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371540bd-f078-417a-bd08-f46c1075c333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmtoolkit.topicmod import tm_sklearn\n",
    "from tmtoolkit.topicmod.visualize import plot_eval_results\n",
    "from tmtoolkit.topicmod.evaluate import results_by_parameter\n",
    "\n",
    "\n",
    "# set constant parameters: these won't change \n",
    "const_params = {\n",
    "    'random_state': 123,  # to make results reproducible\n",
    "}\n",
    "\n",
    "# set varying parameters - these will change and be compared from one model to the next.\n",
    "# keep in mind that more variations means more time! \n",
    "var_params = [{'n_components': k, 'doc_topic_prior':1/k}\n",
    "              # testing from 5 to 50 topics: \n",
    "               for k in range(5, 55, 5)]\n",
    "var_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c151b825-85e8-4679-8a4a-9a61c08b28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train multiple models \n",
    "out = tm_sklearn.evaluate_topic_models(bag_of_words, \n",
    "                                       varying_parameters=var_params, \n",
    "                                       constant_parameters=const_params,\n",
    "                                       return_models=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2c24a7-b525-4073-8fa2-ac1abd9ef586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view results\n",
    "eval_results_by_topics = results_by_parameter(out, 'n_components')\n",
    "\n",
    "eval_results_by_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45991ae2-8d9c-4f8d-8a0b-a2df3ba74a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results. Look for lower values of perplexity and higher values of coherence. \n",
    "plot_eval_results(eval_results_by_topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88b2da-211d-4093-9ce3-6037427169b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fifth model (k = 30) looks like the best performer, so take it out of the results and use it for other analyses\n",
    "best_model = out[5][1]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6edd025-acf4-4b0d-8bff-cecdcfd0da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_functions.get_top_words(best_model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18535f94-3e9a-40b4-a952-1e8e7af6e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_functions.get_top_docs(doctopics, 5, list(articles.hyperlink)).style"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
