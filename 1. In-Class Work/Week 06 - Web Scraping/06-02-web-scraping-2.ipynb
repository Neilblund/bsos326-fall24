{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6414f9-bab0-49df-9ecc-89b0eb226478",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Web Scraping II\n",
    "\n",
    "Use **Code** cells to write and run any code you need to answer the question and **Markdown** cells to write out answers in words. After you are finished with the assignment, remember to download it as an **HTML file** and submit it in **ELMS**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858cce0-71cd-42ff-b18e-4ca87e22a552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from lxml import html \n",
    "from requests import get\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999c8d3-3b67-4d08-8852-94b701ba1a00",
   "metadata": {},
   "source": [
    "## Notes and Key Things to Remember\n",
    "\n",
    "**Make sure you specify your URL correctly!** This holds for both APIs and for web scraping. One of the most common mistakes when using these techniques is that the URL just hasn't been specified correctly, and there's just an error in the request. Steps to take include:\n",
    "- Check your status code, and if you are not getting a 200 status code, try to figure out what went wrong with your URL. \n",
    "- Look at the documentation for APIs and see if you can identify what the base URL you should be using is. Compare the base URL to your base URL to see if it matches.\n",
    "- Navigate to the URL in a browser to see if you can connect to the website and/or see the data.\n",
    "\n",
    "**Identify the exact pieces of data you want to collect.** A webpage will have lots of information on it, and sifting through it all can be daunting. \n",
    "- Use the Selector Gadget to make your life easier. Use the XPath or the `select` method with Beautiful Soup.\n",
    "- Try a few different methods to see what you get. Sometimes, just identifying the correct tag might be easy and useful for grabbing the data you want. Other times, the XPath will be the easiest way.\n",
    "\n",
    "**Cleaning the data is an exercise in Python.** That is, understanding the different Python objects such as lists, dictionaries, and DataFrames is very important. The data that you get will be in sorts of formats (e.g., list of lists, list of dictionaries, just one big list, etc.), so you will need to think about how to work with data in all shapes and sizes.\n",
    "- To begin, identify what the data structure is like in the beginning.\n",
    "- Think about what you want to end up with. This is usually a DataFrame, but what should each row in the DataFrame represent?\n",
    "- Think about what types of data you have. Do you have numeric data? Or do you have strings? Should you do any conversion while you work with your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a1a3c8-a6b8-4b27-b124-01fd68ebdd25",
   "metadata": {},
   "source": [
    "## Beautiful Soup\n",
    "\n",
    "In this notebook, we will continue to work with Beautiful Soup (https://beautiful-soup-4.readthedocs.io/en/latest/), a Python library that is designed to make pulling data out of HTML files easier. \n",
    "\n",
    "As a reminder, the steps for web scraping with Beautiful Soup are:\n",
    "- Get the content using the url of the website you want to scrape and `get` from `requests`.\n",
    "- Parse the content of the website using Beautiful Soup and create a Beautiful Soup object. (This creates a data structure that we can navigate to extract information from)\n",
    "- Look at the source code or use Selector Gadget to identify what you want and where it is within the HTML.\n",
    "- Use tags and methods such as `find_all` or `select` to get the pieces of information you want from the webpage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8315c27d-5a37-4d4c-9f97-71f49c6d8e81",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Beautiful Soup with Selector Gadget\n",
    "\n",
    "So far, we've gone over using the xpath from Selector Gadget, as well as using Beautiful Soup and trying to identify the tags that are associated with each piece of data we want to collect. We can actually also use these together. The Selector Gadget tool gives us what we need to use within the `select` method to grab just the highlighted information. \n",
    "\n",
    "Let's give this a shot with some data from Wikipedia.The first step, as before, is to get the URL of the website we want to scrape. We will scrape data from the University of Maryland Wikipedia page. This page has some basic information about the university, including tables of student composition and admittance information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9772c2d-15e9-450a-81a9-55615fdfc133",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/University_of_Maryland,_College_Park'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa47755-5052-4728-9bb4-da185608067c",
   "metadata": {},
   "source": [
    "We can navigate to the URL to take a look at it. Try opening up Selector Gadget with the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd2e437-2e5b-49f0-bcdf-f836f8d1e8ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedafcfd-8532-48c9-8c37-389f93eca12e",
   "metadata": {},
   "source": [
    "As before, we use `get` to get a response from the website. As long as you don't have a typo in the URL, you should get a 200 status code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6700d3be-c7d0-4a5a-940f-2fcd1c137f7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "webpage = get(url)\n",
    "webpage.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e88d1-f483-4edb-a5d3-8824bcdad90c",
   "metadata": {},
   "source": [
    "Then, we use `BeautifulSoup` to get the webpage content into the Beautiful Soup data structure. This provides the organization that we can then use to extract the information we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ef114-cabc-4020-a2c4-3baf648e460f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(webpage.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c39fd91-eb1b-4d9d-98b0-f9f6cd414ce6",
   "metadata": {},
   "source": [
    "Once we have the parsed HTML information, we can use the `.select` method with our Beautiful Soup object to grab the pieces that we want using the help of Selector Gadget. For example, to grab some information from tables within the Wikipedia article, we can click around until we have the information we want highlighted, then paste the string that shows up at the bottom (NOT the XPath!) as the argument. \n",
    "\n",
    "Let's try to grab the table of admissions information from the Wikipedia page. This should look something like the following:\n",
    "\n",
    "![UMD Admissions Table](umd_table.png)\n",
    "\n",
    "To grab the information from this table, we'll use Selector Gadget to try to select just the information in the table, then use that with the `select` method to hopefully isolate the data we want. Note that it might be very hard to grab only the piece we want, so we might have to deal with getting a bit more information. \n",
    "\n",
    "In the image below you can see the table highlighted. The stuff at the bottom in the Selector Gadget tool that says `\".wikitable td, .wikitable th\"` is what we want to copy and paste and use with the `select` method.\n",
    "\n",
    "![Selector Gadget with the UMD Admissions Table](SelectorGadgetWikipedia.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c969b0e8-9f2b-4194-979f-e89d9b4bc526",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_info = soup.select('.wikitable td , .wikitable th')\n",
    "table_info[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb283fc-88e4-491d-8f32-89e9b58ab103",
   "metadata": {},
   "source": [
    "Note that we have some stuff that we don't necessarily want to include."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43599166-2f4d-4da7-a769-5083c8367f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_info[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aed9e65-10a8-488c-b5d3-2e8f8dbe074d",
   "metadata": {},
   "source": [
    "The information we wanted to get is in a table, so we'll eventually want to get it into a DataFrame format. With this in mind, we'll have to do some work to get the text that's in the tables in a format that is conducive to analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45425768-d4f9-48b5-b962-745f2f8deb01",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 1: Create a list that contains the text of just the table information for University of Maryland applicants (so, not the table information for any other tables that were brought in). Use the `.strip` method to remove any leading or trailing spaces and/or carriage returns.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b043f95f-0612-4f40-ad59-edbd50f36a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b1ee43-a707-4e53-b098-b6667aefd218",
   "metadata": {},
   "source": [
    "Now that we have the information in a list, we need to do some transformation in order to make it into a DataFrame. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09d88e-0069-4746-92c5-269874ad67c2",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 2: Using list comprehension and dictionary comprehension, create a dictionary that has the variable names as keys (Applicants, Admits, Admit rate, etc.) and the values for each year between 2017 and 2022 as the values. Note that you won't have a \"Year\" key since they didn't include \"Year\" within the table originally. Using this dictionary, create a DataFrame called `umd_data`.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599e2e2-f7ff-458c-b57f-d763be2e3071",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee0c54-5618-4caf-807e-974522e8efe7",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 3: Using `apply`, remove all commas from the strings of numbers that have commas. For example, if a value is \"56,766\", it should be updated so that it is just \"56766\". Then, convert all numeric variables into numeric.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4dd4d-e3e8-4d7d-a975-fd16506365aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455cd454-7fad-4164-ae0b-036648e6a15e",
   "metadata": {},
   "source": [
    "Let's do a little bit more cleaning by renaming the blank column to `Year`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2157c83-ecbe-424b-835f-7767bc00ee36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "umd_data.rename(columns = {'':'Year'}, inplace = True)\n",
    "umd_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c08865c-fab8-4b7d-a63f-a2afdc609d52",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 4: Draw a line graph plotting the Admittance rate and Yield rate over the years.**</font>\n",
    "\n",
    "*Hint:* You can use `.plot.line` with the argument `x=` for specifying the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1d9cb1-eef7-48ec-910e-71575b9aefb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e649d1b-44f0-4315-a71e-8336bda663aa",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 5: Create two new variables: `sat_lower` and `sat_upper`, which represent the lower and upper bounds for the middle 50% of students who submitted SAT scores. Make sure that these variables numeric (rather than string). Create a line plot of these.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf73766-84ab-4e7e-8e2f-1e30de7a439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9387e948-b1b6-4f84-96b5-18db8a8169f5",
   "metadata": {},
   "source": [
    "## Extracting Other Information\n",
    "\n",
    "If we wanted to grab the links in a webpage, we can do that as well. This is done by identifying where the link is, then accessing the `href` content. For example, let's get a quick example by searching for all `a` tags and identifying any with `href` in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6dadb-2504-49f3-9d63-2d200ec6e53f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup.find_all('a')[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de356bd-7ae6-41e0-8f91-447cefb4deee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup.find_all('a')[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f72ef8-55a4-4ddb-a113-1c0e1bf02d05",
   "metadata": {},
   "source": [
    "Once we've isolated it, we can simply use `['href']` in order to get that content. Note that these are usually relative links within Wikipedia, so you'll have to do some more work to get a usable URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6dfe3e-ac34-44ee-82d2-1533398d8343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup.find_all('a')[6]['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7b71e-a5f2-4cb8-a7cc-6c6148da82c2",
   "metadata": {},
   "source": [
    "> Hint: This is something that might be useful for grabbing lots of links and looping through them. For example, if you need to loop through lots of counties and navigate to their pages, you can get a list of URLs by grabbing the href content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb40351-9b8e-4646-8bbf-77cc80115f50",
   "metadata": {},
   "source": [
    "## Navigating the Tree\n",
    "\n",
    "Let's go back to the original selection we had done earlier with `table_info`. Note that there is a link, but because of the formatting included within the table, we can't access it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6257c50-4a24-4de9-8c39-7f48705d43a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_info[65]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250018ea-8d9b-4ab1-aab0-30fb5a0f7e68",
   "metadata": {},
   "source": [
    "So, we need to essentially keep going and navigate the tree in order to access it. We'll use `find` to grab the `a` tag, then use that to grab the URL information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49be62d-14e0-4cd8-a1d7-4c3f3127af4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_info[59].find('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb11a23a-b293-4a77-8c93-432d87ead3a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "table_info[59].find('a')['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fbc92b-9bf2-4370-8682-4d80ba520150",
   "metadata": {},
   "source": [
    "Note that again, this is a relative path, so we need to add the Wikipedia URL to make it complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d9187-de95-4ff8-835a-4a6f0864173e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'https://en.wikipedia.org' + table_info[59].find('a')['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd726d-01d0-4106-8671-19eeece0398c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## More Scraping \n",
    "\n",
    "Let's do another example of scraping from the University of Maryland Wikipedia page. Let's grab the information that is on the side box containing some quick facts about the university. \n",
    "\n",
    "<img src=\"umd_facts.png\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a42fe6-1236-412f-a4c5-e3a16507081a",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 6: Using `select`, grab the information in the box (part of the box is shown above). This should have stuff like \"Former names\", \"Motto\", \"Motto in English\", and so on.len(side_info)**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c954e5-d90d-4601-a886-668945a6fbea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4757cb0a-07ab-4ff0-b022-3c1c98249c3d",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 7: Create a dictionary that contains the information, with the keys representing the left-hand column (\"Former names\", \"Motto\", etc.) and the values representing the  values for Maryland.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457779f-345d-4125-b52d-7e685d2d2f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d06c9c-0ab7-4792-9575-06222681d2b0",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 8: Extract the link to the page for \"Public land-grant research university\" from the box.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af32eb2-7aef-4c06-94fb-db37139409f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
