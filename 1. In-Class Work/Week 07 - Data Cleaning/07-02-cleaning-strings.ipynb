{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cleaning Strings\n",
    "\n",
    "Use **Code** cells to write and run any code you need to answer the question and **Markdown** cells to write out answers in words. After you are finished with the assignment, remember to download it as an **HTML file** and submit it in **ELMS**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "import re\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Data\n",
    "\n",
    "String data and needing to clean up string data are very common in social science research. Whether it's coding open response questions in surveys or parsing social media posts, lots of data in the social sciences are text data, and it's important to understand how to deal with them. This is particularly true when using web scraping techniques. The data that you get from web scraping will generally at least start out as string data, which you can then transform into numerical variables as needed.\n",
    "\n",
    "We've already discussed how to deal with individual strings a little bit. For example, recall that we can use f-strings to edit strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year = 2022\n",
    "census_base_url = f'https://api.census.gov/data/{year}/acs/acs1/profile'\n",
    "census_base_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can join strings together using the `+` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'this is' + ' some text.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we have more than two strings that we want to join together, we can instead use the`join` method for strings. Note that this is a **string** method, and so you must use the form `<str>.join(<list>)`. The string is what the separating character will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_list = ['this', 'is', 'some', 'text']\n",
    "\n",
    "' '.join(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'-'.join(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the `replace` method to replace any characters within the string with another character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'This is some text.'.replace(' ', '-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 1: Consider the `wiki_base_url` and `county_list` below. Using these, create a list of URLS that navigate to the corresponding county wikipedia page.**</font>\n",
    "\n",
    "*Note:* The wikipedia page has the format: `https://en.wikipedia.org/wiki/<county_name>,_Maryland`, where any spaces in the county name are replaced by the underscore `_` character. So, for example, the link to Ann Arundel County should be https://en.wikipedia.org/wiki/Anne_Arundel_County,_Maryland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wiki_base_url = 'https://en.wikipedia.org/wiki/'\n",
    "county_list = ['Allegany', 'Anne Arundel', \"Prince George's\"]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Useful String Methods\n",
    "\n",
    "|Method|Description|\n",
    "|-|-|\n",
    "|`join`|Use string as delimiter for concatenating a sequence of other strings|\n",
    "|`find`|Return position of first character of first occurrence of substring in the string; like index, but returns â€“1 if not found|\n",
    "|`strip`|Trim whitespace, including newlines on both sides|\n",
    "|`lower`|Convert alphabet characters to lowercase|\n",
    "|`upper`|Convert alphabet characters to uppercase|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "A **regular expression, or regex**, is a sequence of characters that are used to match patterns within text. These can be extremely useful for searching and matching complicated string patterns. Regexes use specific rules and formatting guidelines to specify various patterns and are implemented in Python via the `re` package. Let's take a look at a quick example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = 'this is some text'\n",
    "re.split(r\"\\s+\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expression `\\s+` refers to one of more whitespace characters. This uses `\\s` as the regex formatting for a whitespace character, as well as the `+` to indicate one or more. Note that `\\s` is used because `s` by itself would refer to the letter `s`. The backslash `\\` is an escape character that allows Python to interpret it as a pattern that it is trying to match.\n",
    "\n",
    "We could have done this without the `+` but that would try to separate on individual spaces instead. In the above example, there would be no difference, but if we were to add additional spaces, we'd see a big change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = 'this is some    text'\n",
    "re.split(r\"\\s\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also first compile a regular expression, then use it multiple times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regex = re.compile(r\"\\s+\")\n",
    "regex.split(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regex.split('some other  text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex methods\n",
    "\n",
    "|Method|Description|\n",
    "|-|-|\n",
    "|`findall`|Return all nonoverlapping matching patterns in a string as a list|\n",
    "|`match`|Match pattern at start of string and optionally segment pattern components into groups; if the pattern matches, return a match object, and otherwise None|\n",
    "|`search`|Scan string for match to pattern, returning a match object if so; unlike match, the match can be anywhere in the string as opposed to only at the beginning|\n",
    "|`split`|Break string into pieces at each occurrence of pattern|\n",
    "|`sub`|Replace all occurrences of pattern in string with replacement expression|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with regex\n",
    "\n",
    "Unless you work with regular expressions frequently, it will be very hard to get good enough at regex to write it out on the fly. Most of the time, you only need regex occasionally for one or two tasks, and it can be hard to remember what all of the patterns and syntax are. **You do not need to try to memorize all of the regex syntax!** There are plenty of tools available to help you out whenever you need to come back to it. Understanding some of the basics should help you get started, and you can use existing cheatsheets as well as online regex builder tools to do the rest. \n",
    "\n",
    "Regex 101 (https://regex101.com) is a website that helps you build your regexes. This website allows you to paste in the text you want to search, as well as type in a regex that you want to build. The text selected by the regex will be highlighted as you go, helping you build the exact regex that you need to get what you want. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex Cheatsheet\n",
    "\n",
    "Feel free to download this cheatsheet to more easily read it. This is also available on the course Canvas website.\n",
    "\n",
    "![Regex Cheatsheet](Regular_Expressions_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strings in DataFrames\n",
    "\n",
    "Many times, we'll have to work with strings that are in DataFrames. These are a bit trickier than individual strings, because we want to be efficient about how we do this. Luckily for us, the creators of the pandas DataFrames recognized that string manipulation would be fairly common and included tools to help make it easier.\n",
    "\n",
    "Let's start by looking at the Pulse of the Nation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '201807-CAH_PulseOfTheNation_Raw.csv'\n",
    "df = pd.read_csv(data_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a relatively clean dataset, with the categories already mostly standardized. However, we might want to still do some additional cleaning or adjusting of the categories. Let's take a look at the `political_party` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.political_party.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the respondent could answer on a scale of how strong their political affiliation was. This can be useful for separating out people who might be swayed one way or another. However, you might also want to do analysis just comparing Democrats and Republicans. To do this, we might want to isolate out everyone who responded as some level of \"Democrat\" or \"Republican\". \n",
    "\n",
    "We could do this with multiple `==` combined with `|`, but that would be a bit tedious (especially with other datasets where there might be more than two categories that we want to combine). Instead, we can use string manipulation with pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.political_party.str.contains('Democrat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`str.contains` returns a `True` if the string contains the pattern given as its argument and `False` otherwise. So, in order to get all Democrats, we can use this to subset our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[df.political_party.str.contains('Democrat')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, using `str.contains` is part of using DataFrame string methods. This was created because string data are extremely common, and so having a way of dealing with each string within a pandas Series is very helpful. Using `.str` with a pandas Series allows us to work with the strings individually instead of having to use `apply` or list comprehension or other types of loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.political_party.str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 2: What is the average age among people who identified as liberal as their political leaning? What is the average age among conservatives?**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## More String Manipulation\n",
    "\n",
    "Let's take another look at the `political_party` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.political_party.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is some inconsistent capitalization. The \"v\" in \"very\" is capitalized for one category but not for another. This is ok in this case, since every case is the same, but it could sometimes lead to issues, because capitalization might cause categories to be not grouped together. For example, this is the case with the `race_other` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.race_other.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The responses for `Mixed race` and `mixed race` are not grouped together because they have inconsistent capitalization. \n",
    "\n",
    "In order to deal with this, one common method is to just lowercase or uppercase everything. That way, we know that there aren't any issues with capitalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.political_party.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.race_other.str.upper().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 3: Create a subset of `df` that contains only the people who identified as not very strong Democrat or Republican.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples with ACS Data\n",
    "\n",
    "Let's look at some simple data from the Census API to get another example of something we might want to do with string variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('census-key.txt', 'r') as f:\n",
    "    census_key = f.readline()\n",
    "\n",
    "census_base_url = 'https://api.census.gov/data/2022/acs/acs1/profile'\n",
    "\n",
    "census_params = {'get':'NAME,DP03_0087E',\n",
    "                 'for':'county:*',\n",
    "                 'key':census_key}\n",
    "\n",
    "r = get(census_base_url, params = census_params)\n",
    "r.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "counties = r.json()\n",
    "counties[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the data into dictionary format\n",
    "keys = ['county', 'mean_income']\n",
    "county_dict = {key:[county[keys.index(key)] for county in counties[1:]] for key in keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've brought in just two variables: the county and the mean income for that county. If we look at a few rows of the dataset, we can see that the county includes the full county name in addition to the state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a DataFrame\n",
    "county_df = pd.DataFrame(county_dict)\n",
    "\n",
    "# Change columns that are numeric to numeric\n",
    "county_df[keys[1]] = county_df[keys[1]].apply(pd.to_numeric)\n",
    "county_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we wanted to get the county name and state name separated from this dataset (we could have gotten this separately from the API, but let's say we are starting with this dataset). We want to split on the comma character `,` so that we have two pieces: the county name and the state name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_df.county[0].split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `.str` to apply this to the all rows of the `county`  variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_df.county.str.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit awkward, though, since we don't want a Series of lists -- we want two columns to add to the DataFrame. Using `expand = True` will give us what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "county_df.county.str.split(',', expand = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then rename the columns using a dictionary to get the split county and state name data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_county = county_df.county.str.split(',', expand = True).rename(columns = {0:'County', 1:'State'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_county.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll merge with the initial DataFrame **on the index** so that we add back in the variables that we had before (just the mean income in this case). Note that this works because we didn't do any subsetting or any other manipulation on the rows and the indices remained the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_county_df = split_county.merge(county_df, left_index = True, right_index = True).drop('county', axis = 1)\n",
    "split_county_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 4: Construct urls for the wikipedia page for each county in this dataset and add that as a column called `wiki_url` to `split_column_df`.**</font>\n",
    "\n",
    "*Hint:* It might be easier to work with the original data without the split County and State names to begin with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regex with DataFrames\n",
    "\n",
    "Suppose we wanted to remove the \"County\" at the end of each county name because it is redundant. We could do a simple `replace` to remove all instances of `County`, but note that there are also `Municipio`s at the end of the ones in Puerto Rico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_county_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get all of these in one go, we can use regular expressions with the `str.replace` method. First, we build a regex object that contains all instances of a space followed by either \"County\" or \"Municipio\". Then, we use `str.replace` to remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regex = re.compile(r'\\s(County|Municipio)')\n",
    "regex.sub('',split_county.County[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 5: Using the `regex` object above, change the `County` variable by removing any instances of the word \"County\" or \"Municipio\".**</font>\n",
    "\n",
    "*Note:* Add an argument `regex = True` in the `replace` method. This explicitly states that you are using a regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
