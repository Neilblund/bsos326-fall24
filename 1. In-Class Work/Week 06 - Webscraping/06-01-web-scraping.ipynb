{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd6414f9-bab0-49df-9ecc-89b0eb226478",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Web Scraping\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d901378f-f6e5-4b48-ac64-5f556cf66173",
   "metadata": {},
   "source": [
    "We'll use some tools from a variety of packages. The `requests` package gives us a way of getting data from the web. This is the main way we will get the actual raw HTML from a webpage. However, that HTML will be very difficult to parse. The `lxml` module gives us a way of interpreting the HTML code and converting it into a text that we can use nicely. \n",
    "\n",
    "Finally, we'll use `pandas` to clean everything up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858cce0-71cd-42ff-b18e-4ca87e22a552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from lxml import html \n",
    "from requests import get\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95cced-4c23-4932-ba06-dce0c26080cc",
   "metadata": {},
   "source": [
    "## Example: Restaurants of the Year from USA Today\n",
    "\n",
    "Suppose we wanted to do a study of what restaurants are considered the best restaurants in the US and do a comparison of the types of cuisines that are featured from different parts of the country. To do this, we might want to grab some information from various sources, such as top restaurants lists, and then try to link that information about the regions that the restaurants are in.\n",
    "\n",
    "Let's take a look at an example of getting some of that information from an article published in USA today about best restaurants in the US. This was a random website I found from a Google search: https://www.usatoday.com/story/life/food-dining/2024/02/15/best-restaurants-of-the-year-across-usa/71909704007/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7369b7f8-be16-483d-95c8-43a280df00f5",
   "metadata": {},
   "source": [
    "First, let's define the URL of the website that we want to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18401a7-4d53-4b70-9761-49b86552e8b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://www.usatoday.com/story/life/food-dining/2024/02/15/best-restaurants-of-the-year-across-usa/71909704007/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1d333-eb49-47e5-86d3-1ccaab44f60d",
   "metadata": {},
   "source": [
    "We then use the `get` function from the `requests` package to get the HTML code from the URL that we specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db291b6f-5d39-4510-bd6a-2d6a15c48331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "webpage = get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec37e0-5403-46cd-a2d8-5d9493db8525",
   "metadata": {},
   "source": [
    "We can check the status code to see if we were able to actually connect to the webpage. We want to see a status code of 200. If you see something else, that's a sign that something went wrong. There are many reasons something might go wrong at this stage, including a typo in the URL, issues with your internet connection, lack of permissions, and so on. The status code can help you diagnose what the issue might be if you don't see 200. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17211d9e-e3a9-4b95-a2b2-2a25b46001ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "webpage.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037d960-7fd1-4740-a12d-7ff4546a3ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree = html.fromstring(webpage.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6890d7-db94-4997-bc4d-d46f5fa2341c",
   "metadata": {},
   "source": [
    "Next, we will use Selector Gadget (https://selectorgadget.com) in order to grab the pieces that we want. This is a nifty tool that you can use with webpages to select and grab only the data that you want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339599c4-1ebc-47ce-9017-724e9933e435",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xp = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"gnt_ar_b_h2\", \" \" ))]//a'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e053abd9-7ec3-4b00-aabe-52c6ebfa7dbc",
   "metadata": {},
   "source": [
    "We use the `xpath` method to pull out the information from just that xpath. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a1b7a-003e-4576-bbd5-e08f5d10a5ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "restaurants = tree.xpath(xp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ff413-eee5-4176-a1a1-98f72725d85f",
   "metadata": {},
   "source": [
    "Then, we can use `.text` to pull out just the text for individual elements of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e91e4b-ec11-4ae9-9e17-aec242523dc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "restaurants[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1c8817-0612-4c1f-bc66-18bde1b28610",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 1: Create a list `names` of restaurant names using the `restaurants` object. These should not contain the location of the restaurant.**</font>\n",
    "\n",
    "*Hint:* For strings, you can use the `.split()` method to split a string on a specific character (such as `|`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6025d4c-54c3-453b-9aac-960607b44e69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c5adda-2822-4433-a18e-5f1bc9ae4f61",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 2: Create a list `locations` of restaurant locations using the `restaurants` object. These should not contain the names of the restaurant.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3b03c4-2b2c-4364-ae5b-8c0f55624377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8edd0a8-8ac9-46e2-89b0-fdd24dfba87f",
   "metadata": {},
   "source": [
    "Next, let's create two lists `city` and `state` that separates out the restaurant locations. We can do the same process of splitting for the `locations` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a91d0a6-1551-4671-969c-14e765e39078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "city = [l.split(', ')[0] for l in locations]\n",
    "city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1154bcf-536f-4344-82f2-9fbdd68e9cd4",
   "metadata": {},
   "source": [
    "Looking at the `city` list, though, we might notice an issue. There might be a typo that means there is a missing comma (Since webpages change, this is not guaranteed to be there. But there was one when I put this together). This means that we need to a bit of cleaning first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc55abd-e58a-4165-b732-f7069681755d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "locations[-7] = 'Nashville, Tennessee'\n",
    "city = [l.split(', ')[0] for l in locations]\n",
    "city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5493129-245c-46da-87ec-913ba8cb1658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "state = [l.split(', ')[1] for l in locations]\n",
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a15ee-e995-4acd-a698-324faa49e417",
   "metadata": {},
   "source": [
    "Once we get the data cleaned up a bit, we can change it into a Pandas Series object to make working with it easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8447aada-e0ff-4c40-b12e-418a114db46e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "restaurants_dict = {'Name':names, 'City':city, \"State\":state}\n",
    "rest_df = pd.DataFrame(restaurants_dict)\n",
    "rest_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46706f73-ccc5-42ce-afa6-fa2e13ac7856",
   "metadata": {
    "tags": []
   },
   "source": [
    "<font color ='red'>**Question 3: Which state had the most restaurants appear on the USA Today list of Best Restaurants in 2024?**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3c192-f82f-47d9-b73c-cfd8df34f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3fba69-5315-4602-95b5-e27735accc98",
   "metadata": {},
   "source": [
    "### Grabbing more information\n",
    "\n",
    "We have now gotten the restaurant name along with City and State. We can keep going and identify other pieces from the webpage that we want to grab. For example, we see that there is a short description for each restaurant. We might want to pull out that text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b65f5f2-166e-4f7b-8602-d5c7078b5a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xp = '//*[contains(concat( \" \", @class, \" \" ), concat( \" \", \"gnt_ar_b_p\", \" \" ))]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf10b04-1e90-4089-aa5c-d5e2c0df8219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree = html.fromstring(webpage.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fd58d-4718-4c02-bb00-4b39e2b6aed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "article_text = [x.text for x in tree.xpath(xp)]\n",
    "article_text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cc7e74-3da2-4c5a-be43-b8275b43f352",
   "metadata": {},
   "source": [
    "This grabbed a bit too much information, so we'll need to cut it down. For example, we can remove the first few elements because it's just the introductory part of the article. There are also some None values in there. Let's clean these up a bit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837fcc46-6eb7-4d19-ba93-1e5c64247780",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "descriptions = [x.text for x in tree.xpath(xp) if x.text is not None][6:]\n",
    "descriptions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cc7d1-f4b6-4a06-bc3f-5b71c18eade4",
   "metadata": {},
   "source": [
    "There's a little more work to be done here before we add this to the `rest_df` DataFrame. You'll notice that the length of this list is a bit longer than the number of rows in the DataFrame. That's because there's a few stray pieces that we still need to clean up. Near the end of the article, there are a few extra paragraphs that aren't about specific restaurants. Also, one restaurant had a two paragraph description, so it's been split up into two. You'll have to manually go in and update those so that it all matches up. \n",
    "\n",
    "Feel free to try giving this a shot. Note that the `.join` method for strings can join together the strings within a list. For example, `' '.join(['some', 'text'])` creates the string `'some text'` because it joins the strings within the list using the space `' '` as the separator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81945912-2880-4ee8-b38c-1f1dd41abc44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "' '.join(['some', 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ef868-dcc9-41c0-88a1-822823b61367",
   "metadata": {},
   "source": [
    "### Notes about using the Selector Gadget method\n",
    "\n",
    "This is a relatively easy way to grab the data you want to from HTML pages. Notably, you don't need to actually know what HTML tags mean, or how to identify them. The Selector Gadget provides a way to do this all by pointing and clicking.\n",
    "\n",
    "However, this can sometimes be finicky and not grab exactly what you want. A more consistent way is to identify the tags exactly and use those. This might mean needing to do a bit more additional cleaning, but you do ensure that you don't miss data or lose out on information.\n",
    "\n",
    "In the next section, we'll talk about another method for grabbing data from HTML files using Beautiful Soup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a1a3c8-a6b8-4b27-b124-01fd68ebdd25",
   "metadata": {},
   "source": [
    "## Using Beautiful Soup\n",
    "\n",
    "Beautiful Soup (https://beautiful-soup-4.readthedocs.io/en/latest/) is a Python library that is designed to make pulling data out of HTML files easier. \n",
    "\n",
    "We'll first take the HTML content, parse it, then extract the pieces we want using the HTML tags that are part of the webpage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93ed575-d871-44ed-bef6-5138d32696c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "webpage = get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1738b15-20f2-460a-b1dd-edd3ec2634f7",
   "metadata": {},
   "source": [
    "We'll create a `BeautifulSoup` data structure from the content that we get from the webpage. This will essentially organize the data so that we can pull out pieces that we want. You can think about this similar to how we organize data in DataFrames (except not in the same tabular format of the DataFrames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc14e4-020a-4f43-ab01-12842492b647",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(webpage.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c11ca9f-144d-4e2b-afb2-4b7fb5ac0624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9bcbdb-27b9-44e9-9674-48ad5017e488",
   "metadata": {},
   "source": [
    " Instead of a tabular structure, though, the data are stored in a tree structure, according to the tags. So, in order to find the data we want, we will need to identify the tags so that we can find the data we want. It can be helpful to look at the HTML source code to identify the pieces of the webpage that we want to pull from. This might involve a little bit of trial and error, but the browser tools should be useful for finding the tags that you want. \n",
    "\n",
    "As a reminder, here is the webpage we are scraping from: https://www.usatoday.com/story/life/food-dining/2024/02/15/best-restaurants-of-the-year-across-usa/71909704007/. \n",
    "\n",
    "We can access different parts of the data in the webpage using the dot notation similar to how we might access columns of a DataFrame. For example, since the restaurant names are in the `h2` tag, we can use `soup.h2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744ba79-c415-4325-b71d-d6890922e065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup.h2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df839e3e-4b02-4ebe-a360-c8597c1768e3",
   "metadata": {},
   "source": [
    "This is a bit messy, but we can use the `get_text()` method to clean it up and get just the relevant text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f88e5c-39b8-4b75-9ab7-00328b57a786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup.h2.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972d854-875d-497f-94fb-a89c6808b3b1",
   "metadata": {},
   "source": [
    "Note that this only provides the first one. To get them all, we can use `.find_all`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fffa6d-6937-42e1-91b2-e08e0299e4fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soup.find_all('h2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4811cf4d-2c1e-44c0-9c43-ae0965477b1f",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 4: Create a list of restaurant names using `soup`.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9d3f0f-fb86-4627-8bf4-d7319c751d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405dc34e-ee20-4392-976b-6f5841a3eb3c",
   "metadata": {},
   "source": [
    "Finding the tags that correspond to the pieces of information you want can be a bit time-consuming, but the Inspect Webpage Source feature of your browser can be very helpful in this. How to access the page source will differ according to the browser you are using, but they should all have some way of clicking on the thing you want to find out what the tag associated with it is. \n",
    "\n",
    "For example, to get the paragraph descriptions of each restaurant, we need to find out what tag it's under. Inspecting the webpage should reveal that it is using the 'p' tag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8539cf-bc3b-471a-ba12-a01560b25c45",
   "metadata": {},
   "source": [
    "<font color ='red'>**Question 5: Pull out the descriptions of each restaurant from `soup` as a list. Make sure there isn't any of the front matter introduction to the article. The first element should be details about \"Urban Bar & Kitchen\".**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2838b-6e76-4c56-b3ba-79262c93df6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dbdf6f-ebfa-496f-97a5-27691250691e",
   "metadata": {},
   "source": [
    "Extra code: example of pulling all of the text descriptions using a loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3056ca0d-0b18-4267-8c7b-39ecc0cef260",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = soup.find_all('h2')\n",
    "textlist = []\n",
    "# loop through each header\n",
    "for head in headers:\n",
    "    # start with empty text\n",
    "    text = ''\n",
    "    newtext=head.find_next_sibling()\n",
    "    # now iterate through the next siblings\n",
    "    while newtext is not None:\n",
    "        newtext=newtext.find_next_sibling()\n",
    "        # stop at the end or when you encounter a new header\n",
    "        if (newtext is None or newtext.name == 'h2'):\n",
    "            textlist.append(text)\n",
    "            break\n",
    "        # if the above conditions aren't met, get the text and add it\n",
    "        text+=  newtext.get_text()\n",
    "\n",
    "\n",
    "\n",
    "# put everything in a data frame\n",
    "rest_descriptions = pd.DataFrame({\"locations\":locations ,\"name\":names,\"description\": textlist})\n",
    "\n",
    "# and print the result\n",
    "rest_descriptions.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
